{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Lab Assignment: Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this lab, you will implement multiple predictive models and compare their performance using different evaluation metrics. You will learn to select the most appropriate model for a dataset based on these comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Installations\n",
    "**Objective:** Ensure all necessary packages are installed and imported for the lab.\n",
    "\n",
    "**Tasks:**\n",
    "1. Install required Python packages: pandas, scikit-learn, matplotlib, numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\w200jrs\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install pandas scikit-learn matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "**Objective:** Import all necessary libraries for data manipulation, modeling, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Explore Dataset\n",
    "**Objective:** Gain a preliminary understanding of the dataset to be used for modeling.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Load the Dataset:** Import the dataset into a Pandas DataFrame.\n",
    "2. **Inspect the Data:** Use Pandas functions to inspect the first few rows, check for missing values, and understand the data types.\n",
    "3. **Summary Statistics:** Generate summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Income  Number_of_Purchases  Target  Customer_Category_B  \\\n",
      "0   56   81228                    6       0                False   \n",
      "1   69   68984                    8       1                False   \n",
      "2   46   60774                    9       0                 True   \n",
      "3   32   22568                    4       0                False   \n",
      "4   60   82592                    1       1                False   \n",
      "\n",
      "   Customer_Category_C  \n",
      "0                False  \n",
      "1                False  \n",
      "2                False  \n",
      "3                False  \n",
      "4                 True  \n",
      "Age                    0\n",
      "Income                 0\n",
      "Number_of_Purchases    0\n",
      "Target                 0\n",
      "Customer_Category_B    0\n",
      "Customer_Category_C    0\n",
      "dtype: int64\n",
      "              Age         Income  Number_of_Purchases      Target\n",
      "count  100.000000     100.000000           100.000000  100.000000\n",
      "mean    43.350000   69474.690000             4.690000    0.520000\n",
      "std     14.904663   29863.619229             2.718047    0.502117\n",
      "min     19.000000   20206.000000             1.000000    0.000000\n",
      "25%     31.750000   43229.750000             2.000000    0.000000\n",
      "50%     42.000000   70325.500000             4.000000    1.000000\n",
      "75%     57.000000   95529.000000             7.000000    1.000000\n",
      "max     69.000000  118806.000000             9.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generate a dataset of customer behavior that is used to predict whether a customer will purchase a product based on their behavior\n",
    "# The dataset contains the following columns: Age,Income,Number_of_Purchases,Customer_Category,Target\n",
    "# The Target column indicates whether the customer made a purchase (1) or not (0).\n",
    "# The goal is to build a model that can predict whether a customer will make a purchase based on their behavior.\n",
    "# Generate a synthetic dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Age': np.random.randint(18, 70, size=100),\n",
    "    'Income': np.random.randint(20000, 120000, size=100),\n",
    "    'Number_of_Purchases': np.random.randint(1, 10, size=100),\n",
    "    'Customer_Category': np.random.choice(['A', 'B', 'C'], size=100),\n",
    "    'Target': np.random.choice([0, 1], size=100)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encode the 'Customer_Category' column\n",
    "df = pd.get_dummies(df, columns=['Customer_Category'], drop_first=True)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "df.to_csv('customer_behavior.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('customer_behavior.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Generate summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Preparation\n",
    "**Objective:** Prepare the data for modeling by handling missing values and encoding categorical variables.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Handle Missing Values:** Deal with any missing values in the dataset.\n",
    "2. **Encode Categorical Variables:** Convert categorical variables into numerical format using techniques like one-hot encoding.\n",
    "3. **Train-Test Split:** Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (70, 5)\n",
      "Test set size: (30, 5)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables (if necessary)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'Training set size: {X_train.shape}')\n",
    "print(f'Test set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementing and Evaluating Multiple Models\n",
    "**Objective:** Build and evaluate multiple predictive models on the dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Implement Models:** Create and train logistic regression, decision tree, random forest, and gradient boosting models.\n",
    "2. **Evaluate Models:** Use accuracy, precision, recall, and F1 score to evaluate the models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.4\n",
      "Logistic Regression Precision: 0.0\n",
      "Logistic Regression Recall: 0.0\n",
      "Logistic Regression F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Implementing Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=5)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_precision = precision_score(y_test, logistic_predictions)\n",
    "logistic_recall = recall_score(y_test, logistic_predictions)\n",
    "logistic_f1 = f1_score(y_test, logistic_predictions)\n",
    "print(f'Logistic Regression Accuracy: {logistic_accuracy}')\n",
    "print(f'Logistic Regression Precision: {logistic_precision}')\n",
    "print(f'Logistic Regression Recall: {logistic_recall}')\n",
    "print(f'Logistic Regression F1 Score: {logistic_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.3\n",
      "Decision Tree Precision: 0.38461538461538464\n",
      "Decision Tree Recall: 0.2777777777777778\n",
      "Decision Tree F1 Score: 0.3225806451612903\n"
     ]
    }
   ],
   "source": [
    "# Implementing Decision Tree\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_predictions = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
    "tree_precision = precision_score(y_test, tree_predictions)\n",
    "tree_recall = recall_score(y_test, tree_predictions)\n",
    "tree_f1 = f1_score(y_test, tree_predictions)\n",
    "print(f'Decision Tree Accuracy: {tree_accuracy}')\n",
    "print(f'Decision Tree Precision: {tree_precision}')\n",
    "print(f'Decision Tree Recall: {tree_recall}')\n",
    "print(f'Decision Tree F1 Score: {tree_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.4\n",
      "Random Forest Precision: 0.5\n",
      "Random Forest Recall: 0.2777777777777778\n",
      "Random Forest F1 Score: 0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Implementing Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions)\n",
    "rf_recall = recall_score(y_test, rf_predictions)\n",
    "rf_f1 = f1_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest Precision: {rf_precision}')\n",
    "print(f'Random Forest Recall: {rf_recall}')\n",
    "print(f'Random Forest F1 Score: {rf_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.3333333333333333\n",
      "Gradient Boosting Precision: 0.4375\n",
      "Gradient Boosting Recall: 0.3888888888888889\n",
      "Gradient Boosting F1 Score: 0.4117647058823529\n"
     ]
    }
   ],
   "source": [
    "# Implementing Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "gb_precision = precision_score(y_test, gb_predictions)\n",
    "gb_recall = recall_score(y_test, gb_predictions)\n",
    "gb_f1 = f1_score(y_test, gb_predictions)\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "print(f'Gradient Boosting Precision: {gb_precision}')\n",
    "print(f'Gradient Boosting Recall: {gb_recall}')\n",
    "print(f'Gradient Boosting F1 Score: {gb_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparing Model Performance\n",
    "**Objective:** Compare the performance of logistic regression, decision tree, random forest, and gradient boosting models.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Compare Metrics:** Print and compare the accuracy, precision, recall, and F1 scores of all models.\n",
    "2. **Model Selection:** Discuss which model performed best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.4, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n",
      "Decision Tree Accuracy: 0.3, Precision: 0.38461538461538464, Recall: 0.2777777777777778, F1 Score: 0.3225806451612903\n",
      "Random Forest Accuracy: 0.4, Precision: 0.5, Recall: 0.2777777777777778, F1 Score: 0.35714285714285715\n",
      "Gradient Boosting Accuracy: 0.3333333333333333, Precision: 0.4375, Recall: 0.3888888888888889, F1 Score: 0.4117647058823529\n"
     ]
    }
   ],
   "source": [
    "# Compare model performance\n",
    "print(f'Logistic Regression Accuracy: {logistic_accuracy}, Precision: {logistic_precision}, Recall: {logistic_recall}, F1 Score: {logistic_f1}')\n",
    "print(f'Decision Tree Accuracy: {tree_accuracy}, Precision: {tree_precision}, Recall: {tree_recall}, F1 Score: {tree_f1}')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}, Precision: {rf_precision}, Recall: {rf_recall}, F1 Score: {rf_f1}')\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}, Precision: {gb_precision}, Recall: {gb_recall}, F1 Score: {gb_f1}')\n",
    "\n",
    "# Discuss model performance\n",
    "# (Provide your analysis here based on the results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Using Cross-Validation for Model Evaluation\n",
    "**Objective:** Apply cross-validation to evaluate the stability and reliability of model performance.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Perform Cross-Validation:** Use cross-validation to evaluate the models' performance.\n",
    "2. **Interpret Results:** Analyze cross-validation results to understand model reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\w200jrs\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores: [0.5  0.5  0.5  0.45 0.55]\n",
      "Decision Tree Cross-Validation Scores: [0.35 0.4  0.65 0.3  0.4 ]\n",
      "Random Forest Cross-Validation Scores: [0.45 0.45 0.5  0.45 0.55]\n",
      "Gradient Boosting Cross-Validation Scores: [0.45 0.45 0.6  0.3  0.35]\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "logistic_cv_scores = cross_val_score(logistic_model, X, y, cv=5)\n",
    "tree_cv_scores = cross_val_score(tree_model, X, y, cv=5)\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "gb_cv_scores = cross_val_score(gb_model, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f'Logistic Regression Cross-Validation Scores: {logistic_cv_scores}')\n",
    "print(f'Decision Tree Cross-Validation Scores: {tree_cv_scores}')\n",
    "print(f'Random Forest Cross-Validation Scores: {rf_cv_scores}')\n",
    "print(f'Gradient Boosting Cross-Validation Scores: {gb_cv_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Submission\n",
    "**Deliverables:**\n",
    "- Jupyter Notebook (.ipynb) with all code and model evaluations.\n",
    "- A brief report (1-2 paragraphs) summarizing the findings, comparing model performance, and discussing the best model choice based on evaluation metrics and cross-validation results.\n",
    "\n",
    "**Deadline:** Submit your completed notebook and report to the course portal by the end of class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
