{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Lab Assignment: Decision Trees, Random Forest, Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this lab, you will implement decision tree models, random forest, and gradient boosting using Python. You will learn how to build these models, understand their differences, and evaluate their performance on a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Explore Dataset\n",
    "**Objective:** Gain a preliminary understanding of the dataset to be used for modeling.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Load the Dataset:** Import the dataset into a Pandas DataFrame.\n",
    "2. **Inspect the Data:** Use Pandas functions to inspect the first few rows, check for missing values, and understand the data types.\n",
    "3. **Summary Statistics:** Generate summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2 Feature3  Target\n",
      "0      35.1       0.5        A       0\n",
      "1      42.2       1.1        B       1\n",
      "2      28.7       0.7        A       0\n",
      "3      54.5       1.5        C       1\n",
      "4      47.8       1.2        B       1\n",
      "Feature1    0\n",
      "Feature2    0\n",
      "Feature3    0\n",
      "Target      0\n",
      "dtype: int64\n",
      "        Feature1   Feature2     Target\n",
      "count  30.000000  30.000000  30.000000\n",
      "mean   44.226667   1.126667   0.466667\n",
      "std    11.092524   0.435441   0.507416\n",
      "min    25.900000   0.400000   0.000000\n",
      "25%    35.225000   0.800000   0.000000\n",
      "50%    44.050000   1.050000   0.000000\n",
      "75%    54.300000   1.500000   1.000000\n",
      "max    62.800000   1.900000   1.000000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_behavior.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Generate summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "**Objective:** Prepare the data for modeling by handling missing values and encoding categorical variables.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Handle Missing Values:** Deal with any missing values in the dataset.\n",
    "2. **Encode Categorical Variables:** Convert categorical variables into numerical format using techniques like one-hot encoding.\n",
    "3. **Train-Test Split:** Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (21, 4)\n",
      "Test set size: (9, 4)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables (if necessary)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'Training set size: {X_train.shape}')\n",
    "print(f'Test set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementing Decision Tree Model\n",
    "**Objective:** Build and evaluate a decision tree model on the dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Build the Model:** Create a decision tree classifier using Scikit-learn.\n",
    "2. **Train the Model:** Train the model on the training data.\n",
    "3. **Evaluate the Model:** Use accuracy and classification report to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.90      0.90      0.89         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build and train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(classification_report(y_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implementing Random Forest Model\n",
    "**Objective:** Build and evaluate a random forest model on the dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Build the Model:** Create a random forest classifier using Scikit-learn.\n",
    "2. **Train the Model:** Train the model on the training data.\n",
    "3. **Evaluate the Model:** Use accuracy and classification report to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.90      0.90      0.89         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementing Gradient Boosting Model\n",
    "**Objective:** Build and evaluate a gradient boosting model on the dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Build the Model:** Create a gradient boosting classifier using Scikit-learn.\n",
    "2. **Train the Model:** Train the model on the training data.\n",
    "3. **Evaluate the Model:** Use accuracy and classification report to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.90      0.90      0.89         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build and train the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "print(classification_report(y_test, gb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparing Model Performance\n",
    "**Objective:** Compare the performance of decision tree, random forest, and gradient boosting models.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Compare Accuracy:** Print and compare the accuracy of all models.\n",
    "2. **Model Selection:** Discuss which model performed best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8888888888888888\n",
      "Random Forest Accuracy: 0.8888888888888888\n",
      "Gradient Boosting Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Compare model accuracy\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "\n",
    "# Discuss model performance\n",
    "# (Provide your analysis here based on the results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Submission\n",
    "**Deliverables:**\n",
    "- Jupyter Notebook (.ipynb) with all code and model evaluations.\n",
    "brief report (1-2 paragraphs) summarizing the findings, comparing model performance, and discussing the application of SEMMA and CRISP-DM methodologies.\n",
    "\n",
    "**Deadline:** Submit your completed notebook and report to the course portal by end of class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
